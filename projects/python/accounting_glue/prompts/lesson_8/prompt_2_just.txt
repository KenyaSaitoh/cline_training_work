===============================================
ETL実装プロンプト【中：適切版】
===============================================

上流システム（売上・人事・在庫）から会計システムへのデータ統合ETL処理を、3つの実行方式で実装してください。

## 1. アーキテクチャ原則

**共通変換ロジック（`src/etl/`）を環境非依存で実装し、3つの実行環境（Python標準版/PySpark版/AWS Glue版）で共通利用します。**

```
[共通] src/etl/Transformer
    ↓ 同じロジック
[実行環境①] Python標準版（ThreadPool）
[実行環境②] PySpark版（RDD）
[実行環境③] AWS Glue版（S3 + RDD）
```

---

## 2. 実装対象

### 2.1 共通変換ロジック（`src/etl/`）

3つのTransformerを実装：
- **SalesTransformer**: 売上データ変換
- **HRTransformer**: 人事データ変換（**2つのCSVをジョイン**）
- **InventoryTransformer**: 在庫データ変換

**重要**: HRは`hr_employee_org_export.csv`（従業員マスタ）と`hr_payroll_export.csv`（給与実績）を`employee_id`でINNER JOINして処理します。

**変換仕様**: `spec/detail_design/`配下の各MDファイル参照  
**DDL**: `ddl/source/`配下のSQLファイル参照

### 2.2 共通モジュール（`src/common/`）

- **config.py**: 勘定科目マッピング、システム固定値
- **csv_handler.py**: CSV読み込み/書き込み
- **utils.py**: バッチID生成、日時フォーマット、ロギング

### 2.3 実行環境別のラッパー

#### ①Python標準版（`src/local/python_native/`）
- 3つのスタンドアロンジョブを実装
- ThreadPoolExecutorで並列処理
- 小規模データ向け（〜1万レコード）

#### ②PySpark版（`src/local/pyspark/`）
- 3つのPySparkジョブを実装
- RDD.map()で分散処理
- 大規模データ向け（10万レコード〜）

#### ③AWS Glue版（`src/aws_glue/`）
- 3つのGlueジョブスクリプトを実装
- S3読み込み/書き込み
- 本番環境

### 2.4 オーケストレーター（`src/local/etl_orchestrator.py`）

3つのETLジョブを並列実行し、個別出力ファイルを統合して`accounting_txn_interface.csv`を生成。

---

## 3. テスト

### 単体テスト（`tests/unit/`）
各Transformerの変換ロジックをテスト（pytest）

### 統合テスト（`tests/integration/`）
ETL出力ファイルと期待値データ（`test_data/expected/`）を照合

---

## 4. 実装の優先順位

1. 共通モジュール（config、csv_handler、utils）
2. 3つのTransformer + 単体テスト
3. Python標準版（3ジョブ）
4. PySpark版（3ジョブ）
5. AWS Glue版（3ジョブ）
6. オーケストレーター + 統合テスト

---

## 5. 参照資料

**必ず参照してください：**
- **変換仕様**: `spec/detail_design/*.md`（各システムの変換ロジック詳細）
- **DDL**: `ddl/source/*.sql`（入力データ構造）、`ddl/erp/*.sql`（出力データ構造）
- **アーキテクチャ**: `ARCHITECTURE.md`
- **実行方法**: `README.md`
