===============================================
ETL実装プロンプト【高：詳細版】
===============================================

上流システム（売上・人事・在庫）から会計システムへのデータ統合ETL処理を実装してください。

## 1. アーキテクチャ原則

**共通変換ロジックと環境固有ラッパーの分離**

```
[共通変換ロジック: src/etl/]
  ├── SalesTransformer
  ├── HRTransformer
  └── InventoryTransformer
      ↓ 同じロジック
[実行方式①] Python標準版（ThreadPool）
[実行方式②] PySpark版（RDD）
[実行方式③] AWS Glue版（S3 + RDD）
```

**重要**: ローカルでテストしたコードが本番（AWS Glue）でもそのまま動作。

---

## 2. 共通変換ロジック（`src/etl/`）

### 2.1 SalesTransformer（`sales_transformer.py`）

**入力**: `sales_txn_export.csv`

**変換内容**:
- トランザクションタイプ別の勘定科目マッピング
- 税額計算と外貨換算
- 必須項目バリデーション

**仕様参照**: `spec/detail_design/sales_txn_export.md`、`ddl/source/sales_txn_export.sql`

### 2.2 HRTransformer（`hr_transformer.py`）

**入力**: 
1. `hr_employee_org_export.csv`（従業員マスタ）
2. `hr_payroll_export.csv`（給与実績）
3. **ジョイン**: `employee_id`をキーにINNER JOIN

**変換内容**:
- 給与項目別の勘定科目マッピング
- 1従業員から複数仕訳を生成（基本給・手当・控除ごと）
- 片側記録方式（対側は会計システムで自動生成）

**仕様参照**: `spec/detail_design/hr_employee_org_export.md`（セクション4.3: ジョイン処理）、`ddl/source/hr_*.sql`

### 2.3 InventoryTransformer（`inventory_transformer.py`）

**入力**: `inv_movement_export.csv`

**変換内容**:
- 移動タイプ別の勘定科目マッピング（RCV/ISS/ADJ）
- 原価計算（quantity × unit_cost）

**仕様参照**: `spec/detail_design/inv_movement_export.md`、`ddl/source/inv_movement_export.sql`

---

## 3. 共通モジュール（`src/common/`）

- **config.py**: 勘定科目コード、ステータスコード、エラーコード
- **csv_handler.py**: CSV読み込み/書き込み
- **utils.py**: バッチID生成、日時フォーマット、金額丸め、ロギング

---

## 4. 実行方式別の実装

### 4.1 ①Python標準版（`src/local/python_native/`）

3つのスタンドアロンジョブ:
- `standalone_sales_etl_job.py`
- `standalone_hr_etl_job.py`
- `standalone_inventory_etl_job.py`

**処理フロー**:
```
CSV読み込み → ThreadPoolExecutor.map(transform) → CSV書き込み
```

**実行方法**:
```bash
# 個別実行
python src/local/python_native/standalone_sales_etl_job.py --limit 100
python src/local/python_native/standalone_hr_etl_job.py --limit 100
python src/local/python_native/standalone_inventory_etl_job.py --limit 100

# オーケストレーター経由（推奨）
python src/local/etl_orchestrator.py --mode python --limit 100
```

### 4.2 ②PySpark版（`src/local/pyspark/`）

3つのPySparkジョブ:
- `pyspark_sales_etl_job.py`
- `pyspark_hr_etl_job.py`
- `pyspark_inventory_etl_job.py`

**処理フロー**:
```
spark.read.csv → RDD.map(transform) → collect() → CSV書き込み
```

**重要な設定**:
- `PYTHONPATH`をプロジェクトルートに設定（ワーカープロセスで`src`モジュールを認識させるため）
- `spark.executorEnv.PYTHONPATH`をSparkConfigで設定

**実行方法**:
```bash
# スクリプトを使用（推奨、PYTHONPATH自動設定）
./run_pyspark_etl.sh sales --limit 100
./run_pyspark_etl.sh hr --limit 100
./run_pyspark_etl.sh inventory --limit 100
./run_pyspark_etl.sh all --limit 100

# オーケストレーター経由
python src/local/etl_orchestrator.py --mode pyspark --limit 1000

# 個別ジョブ直接実行の場合
export PYTHONPATH=$PWD:$PYTHONPATH
python src/local/pyspark/pyspark_sales_etl_job.py --limit 100
```

### 4.3 ③AWS Glue版（`src/aws_glue/`）

3つのGlueジョブスクリプト:
- `glue_sales_etl_job.py`
- `glue_hr_etl_job.py`
- `glue_inventory_etl_job.py`

**処理フロー**:
```
S3読み込み → RDD.map(transform) → S3書き込み
```

**必要なパラメータ**:
- `--input_path` (または `--employee_path`/`--payroll_path` for HR)
- `--output_path`
- `--batch_id` (optional)

### 4.4 オーケストレーター（`src/local/etl_orchestrator.py`）

**機能**:
- 3つのETLジョブをThreadPoolExecutorで並列実行
- 個別出力を`merge_csv_files()`で統合
- Python標準版とPySpark版の両方をサポート

**実行方法**:
```bash
# Python標準版モード
python src/local/etl_orchestrator.py --mode python --limit 100

# PySpark版モード
python src/local/etl_orchestrator.py --mode pyspark --limit 1000

# 全件処理
python src/local/etl_orchestrator.py --mode python
```

**出力ファイル**:
- `output/accounting_txn_interface_sales.csv`
- `output/accounting_txn_interface_hr.csv`
- `output/accounting_txn_interface_inv.csv`
- `output/accounting_txn_interface.csv` ← 統合ファイル

---

## 5. テスト実装

### 5.1 単体テスト（`tests/unit/test_etl/`）

各Transformerの変換ロジックをテスト（40+ test cases）:

**`test_sales_transformer.py`** (15+ tests):
- 正常系: INVOICE/SHIP/PMT変換、外貨換算、税額計算
- 異常系: 必須項目不足、ゼロ単価、不正な通貨コード
- 一側記録方式: INVOICE/SHIP→貸方のみ、PMT→借方のみ

**`test_hr_transformer.py`** (15+ tests):
- 従業員データジョイン処理
- 複数エントリ生成（1従業員→給与+手当+控除）
- 一側記録方式: 支給→借方、控除→貸方
- ゼロ金額フィルタリング

**`test_inventory_transformer.py`** (15+ tests):
- 移動タイプ別処理（RCV/ISS/ADJ）
- 数量に基づく勘定科目決定（ADJ: 増加→1300、減少→5200）
- 一側記録方式: 全て借方のみ

**実行**: `pytest tests/unit/ -v`

### 5.2 統合テスト（`tests/integration/`）

**`test_etl_output.py`**:
- ETL出力ファイルと期待値データ（`test_data/expected/*.csv`）を照合
- レコード数検証、カラム値検証、集計値検証

**`test_orchestrator.py`** (10+ tests):
- 並列実行の動作確認
- マージ処理の検証
- 全ソースシステムのデータ統合確認
- 出力構造の検証
- パフォーマンステスト（並列実行が順次実行より速いこと）

**実行**: `pytest tests/integration/ -v`

---

## 6. 実装の優先順位

**フェーズ1**: 共通モジュール（config、csv_handler、utils）  
**フェーズ2**: 3つのTransformer + 単体テスト  
**フェーズ3**: Python標準版（3ジョブ）  
**フェーズ4**: PySpark版（3ジョブ）  
**フェーズ5**: AWS Glue版（3ジョブ）  
**フェーズ6**: オーケストレーター + 統合テスト

---

## 7. 参照資料（必読）

### 変換仕様（詳細）
- `spec/detail_design/sales_txn_export.md`
- `spec/detail_design/hr_employee_org_export.md`（**セクション4.3: ジョイン処理**）
- `spec/detail_design/inv_movement_export.md`

### DDL
- **入力**: `ddl/source/`（sales_txn_export.sql、hr_employee_org_export.sql、**hr_payroll_export.sql**、inv_movement_export.sql）
- **出力**: `ddl/erp/accounting_txn_interface.sql`

### アーキテクチャ
- `ARCHITECTURE.md`
- `README.md`
